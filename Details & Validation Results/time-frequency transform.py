import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
import torchvision.transforms as transforms
from encoder import *
from PIL import Image

#Perform time-frequency transformation on the collected data and data generated by the model.

model2 = Generator().cuda()
model2.load_state_dict(torch.load('model1/model59.pt'))
model2.eval()

ResNet = make_model()

image_path = r"E:\pycharm projeces\vibrotactile display\data\T5.png" #The folder path corresponding to the texture images.
force_path = r"E:\pycharm projeces\vibrotactile display\data\5-force.xlsx" #The path corresponding to the force signals.
speed_path = r"E:\pycharm projeces\vibrotactile display\data\5-speed.xlsx"#The path corresponding to the velocity signals.
acc_path = r"E:\pycharm projeces\vibrotactile display\data\5-acc.xlsx"#The path corresponding to the vibration acceleration signals.

force = pd.read_excel(force_path).iloc[:, 0].tolist()
speed = pd.read_excel(speed_path).iloc[:, 0].tolist()
acc = pd.read_excel(acc_path).iloc[:, 0].tolist()

def rgb_to_gray(image):
    gray_image = image.convert('L')
    gray_image_rgb = gray_image.convert('RGB')
    return gray_image_rgb

def Feature(image_path):
    image = transforms.ToTensor()(rgb_to_gray(Image.open(image_path))).unsqueeze(0)
    image_feature = ResNet(image).flatten().tolist()
    return image_feature

def rmse(predictions,targets):
    return torch.sqrt(torch.mean((predictions-targets)**2))

image_feature = Feature(image_path)
print(len(image_feature))

real= []
generate= []

for i in range(50):
    list1 = []
    list1 += image_feature
    list1 += speed[200 + 20 * i:20 * i + 220]
    list1 += force[200 + 20 * i:20 * i + 220]
    list1 += acc[20 * i:20 * i + 220]
    print(len(list1))
    csv = torch.tensor(list1).unsqueeze(0).to(device)
    x_t, x_pred_t = model2(csv)
    x_t = x_t.flatten().tolist()
    real+= x_t
    x_pred_t = x_pred_t.flatten().tolist()
    generate += x_pred_t

plt.plot(real)
plt.plot(generate)
plt.show()
plt.cla()

data = real[:500]
data1 = generate[:500]

fft_result = np.fft.fft(data)
N = len(fft_result)
fs = 1000
frequencies = np.fft.fftfreq(N, 1/fs)

fft_result1 = np.fft.fft(data1)
N1 = len(fft_result1)
fs1 = 1000
frequencies1 = np.fft.fftfreq(N1, 1/fs1)

magnitude = np.abs(fft_result)*10
magnitude1 = np.abs(fft_result1)*10

half_N = N // 2
frequencies = frequencies[:half_N]
magnitude = magnitude[:half_N] *2 / half_N
magnitude1 = magnitude1[:half_N] *2 / half_N

predictions = torch.tensor(magnitude)
targets = torch.tensor(magnitude1)
print(rmse(predictions,targets))

plt.figure(figsize=(10, 6))
plt.plot(magnitude)
plt.plot(magnitude1)
plt.title('Single-Sided FFT Magnitude Spectrum')
plt.xlabel('Frequency (Hz)')
plt.ylabel('Magnitude')
plt.grid()
plt.show()